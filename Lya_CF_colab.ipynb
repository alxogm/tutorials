{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNanPUNOggDoua3//Hg0zCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alxogm/tutorials/blob/lyaforest/Lya_CF_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation Function of the Lyman-$\\alpha$ forest in  EDR\n",
        "\n",
        "October 2023\n",
        "\n",
        "Alma Gonz√°lez (U. of Guanajuato)\n",
        "\n",
        "This notebook has been tested in Colaboratory in October 2023.\n",
        "\n",
        "### Table of Contents\n",
        "* [Overview](#overview)\n",
        "* [Installs, Imports and Downloads](#imports)\n",
        "* [Accessing the Data](#data)\n",
        "* [Auto-correlation](#autocorrelation)\n",
        "\n",
        "<a class=\"anchor\" id=\"overview\"></a>\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to use the delta (flux fluctuations) files provided as Lyman-$\\alpha$ catalog value added catalog, as part of the DESI Early Data Release. We will compute the auto-correlation function of the Lyman-$\\alpha$ forest. Finally we will compare our results with those reported by the DESI collaboration in [Gordon et.al. 2023](https://arxiv.org/abs/2308.10950)\n",
        "\n",
        "## Bug Reporting\n",
        "\n",
        "If you identify any errors please talk to me (gonzalez.alma@ugto.mx) as this specific tutorial is not yet in the main desihub repository.\n",
        "\n",
        "<a class=\"anchor\" id=\"imports\"></a>\n",
        "## Installs, Imports and Downloads\n",
        "\n"
      ],
      "metadata": {
        "id": "IRoxui_BL1FX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxkpKc_wdkdp"
      },
      "outputs": [],
      "source": [
        "!pip install picca"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from   google.colab import drive\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import bs4\n",
        "import requests\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import picca\n",
        "from picca.wedgize import wedge\n",
        "import fitsio\n",
        "from astropy.table import Table"
      ],
      "metadata": {
        "id": "nc9dp_5vwG0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount the Drive and define some useful paths\n",
        "drivepath='/content/drive/'\n",
        "drive.mount(drivepath, force_remount=True)\n",
        "desiedr_path = drivepath + '/MyDrive/Bucaramanga/desi_edr/'\n",
        "desicode_path = desiedr_path+'/desicode'\n",
        "specprod = 'fuji'    # Internal name for the EDR\n",
        "specprod_dir = desiedr_path+specprod\n",
        "lya_dir = specprod_dir+'/lya'"
      ],
      "metadata": {
        "id": "eFkaxIfmd8dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.insert(1,desicode_path+\"/desitarget/py/\")\n",
        "sys.path.insert(1,desicode_path+\"/desiutil/py/\")\n",
        "sys.path.insert(1,desicode_path+\"/desispec/py/\")\n",
        "sys.path.insert(1,desicode_path+\"/desimodel/py/\")\n",
        "sys.path.insert(1,desicode_path+'/speclite/')\n",
        "import desispec.io"
      ],
      "metadata": {
        "id": "E9YfDsrhmvxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create some necesary directories\n",
        "if not os.path.exists(lya_dir):\n",
        "  os.makedirs(lya_dir)\n",
        "\n",
        "if not os.path.exists(lya_dir+'/Delta'):\n",
        "  os.makedirs(lya_dir+'/Delta')\n",
        "\n",
        "if not os.path.exists(lya_dir+'/Log'):\n",
        "  os.makedirs(lya_dir+'/Log')\n",
        "\n",
        "if not os.path.exists(lya_dir+'/Correlations'):\n",
        "  os.makedirs(lya_dir+'/Correlations')"
      ],
      "metadata": {
        "id": "yW58cb_8wT25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"data\"></a>\n",
        "## Accessing the data\n",
        "In this case the data is the Lyman-$\\alpha$ catalog, or what we usually refers to as the \"Deltas\". These are a value added catalog of the DESI EDR, and all documentation can be found [here](https://data.desi.lbl.gov/doc/releases/edr/vac/lymanalpha/), and the relevant reference is [Cesar Ramirez-Perez et. al. 2023](https://arxiv.org/abs/2306.06312) ... For a very basic, but practical, introduction of how these deltas are computed see this [desihigh notebook](https://github.com/michaelJwilson/desihigh/blob/main/Lymanalphaforest_explorers.ipynb)"
      ],
      "metadata": {
        "id": "p2Xfl8uiPAnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the Delta Files\n",
        "#you only need to do this the first time, so you can comment the following lines later if you prefer\n",
        "\n",
        "url = \"https://data.desi.lbl.gov/public/edr/vac/edr/lya/fuji/v0.3/Delta/\"\n",
        "r = requests.get(url)\n",
        "data = bs4.BeautifulSoup(r.text, \"html.parser\")\n",
        "for l in data.find_all(\"a\")[1:]:\n",
        "    r = requests.get(url + l[\"href\"])\n",
        "    local_delta=lya_dir+'/Delta/'+l[\"href\"]\n",
        "    if not os.path.exists(local_delta):\n",
        "      tmp = urllib.request.urlretrieve(url + l[\"href\"],local_delta)\n",
        "      print (\"Downloaded file \"+local_delta)\n",
        "    else: continue\n",
        "print(\"All Delta files are on disk\")"
      ],
      "metadata": {
        "id": "vXSmVtoIxnSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lest explore the content of one of the delta files and the attributes file."
      ],
      "metadata": {
        "id": "iUEXQUAQP7t7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_1=fitsio.FITS(\"/content/drive/MyDrive/Bucaramanga/desi_edr/fuji/lya/Delta/delta-1.fits.gz\")\n",
        "print(delta_1)"
      ],
      "metadata": {
        "id": "k26pozRzQAz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata=Table(delta_1[\"METADATA\"][:])\n",
        "tids=metadata[\"TARGETID\"]\n",
        "print(tids)"
      ],
      "metadata": {
        "id": "_AxZNjheQrMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wavelength=delta_1[\"LAMBDA\"][:]\n",
        "deltas=delta_1[\"DELTA\"][:,:]"
      ],
      "metadata": {
        "id": "e5y-OzJwlgkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before proceding to look at the Deltas, lets look at the full spectra. For this, first we need to locate the files where these are stored. So we need to locate them in the redshift catalog."
      ],
      "metadata": {
        "id": "spi2U8CfX0gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zcat=Table.read(specprod_dir+\"/zcatalog/zall-pix-fuji.fits\")"
      ],
      "metadata": {
        "id": "MgBAIo3wYEnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Note I have selected only those that have\n",
        "w=np.in1d(zcat[\"TARGETID\"],tids)\n",
        "zcat=zcat[w]"
      ],
      "metadata": {
        "id": "QArQZoorZaC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets select target ids that are in the same file, we do this by counting how many targetids correspond to the same healpix\n",
        "hpx,indx,counts=np.unique(zcat[\"HEALPIX\"],return_counts=True,return_index=True)\n",
        "max_indx=np.argmax(counts)\n",
        "hpx[max_indx],counts[max_indx],indx[max_indx]"
      ],
      "metadata": {
        "id": "tCRK_3NZeSM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zcat=zcat[zcat[\"HEALPIX\"]==hpx[max_indx]]\n",
        "zcat"
      ],
      "metadata": {
        "id": "6FBgQ236eyl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We use a similar function that in the tutorial\n",
        "def get_spec_data_url(hpx,survey,program,redrock=False):\n",
        "    specprod_dir = f\"https://data.desi.lbl.gov/public/edr/spectro/redux/{specprod}\"\n",
        "    target_dir   = f\"/healpix/{survey}/{program}/{hpx.astype(str)[:-2]}/{hpx}/\"\n",
        "    coadd_fname  = f\"coadd-{survey}-{program}-{hpx}.fits\"\n",
        "\n",
        "    #Download the spectra file to the drive directory mantaining the same structure directory\n",
        "    if not os.path.exists(desiedr_path+'/fuji'+target_dir):\n",
        "      os.makedirs(desiedr_path+'/fuji'+target_dir)\n",
        "\n",
        "    coadd_url = specprod_dir+target_dir+coadd_fname\n",
        "    coadd_file=desiedr_path+'/fuji'+target_dir+coadd_fname\n",
        "\n",
        "    if not os.path.exists(coadd_file):\n",
        "        print(\"downloading coadd file from %s to %s\"\n",
        "              % (coadd_url, coadd_file))\n",
        "        tmp = urllib.request.urlretrieve(coadd_url, coadd_file)\n",
        "    else:\n",
        "        print('%s present on disk. '%(coadd_file))\n",
        "\n",
        "    if redrock:\n",
        "      redrock_fname  = f\"redrock-{survey}-{program}-{hpx}.fits\"\n",
        "      redrock_url = specprod_dir+target_dir+redrock_fname\n",
        "      redrock_file=desiedr_path+'/fuji'+target_dir+redrock_fname\n",
        "\n",
        "      if not os.path.exists(redrock_file):\n",
        "          print(\"downloading coadd from %s to %s\"\n",
        "              % (redrock_url, coadd_file))\n",
        "          tmp = urllib.request.urlretrieve(redrock_url, redrock_file)\n",
        "      else:\n",
        "          print('%s present on disk. '%(redrock_file))\n",
        "\n",
        "    coadd_obj  = desispec.io.read_spectra(coadd_file)\n",
        "    return coadd_obj"
      ],
      "metadata": {
        "id": "vuzB3EnzgA0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coadd_spec=get_spec_data_url(hpx[max_indx],'sv1','dark')"
      ],
      "metadata": {
        "id": "ohhgfaGJgjGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w=np.in1d(coadd_spec.fibermap[\"TARGETID\"],zcat[\"TARGETID\"])\n",
        "coadd_spec_=coadd_spec[w]\n",
        "coadd_spec_.fibermap"
      ],
      "metadata": {
        "id": "Z0hxLiosg3OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(coadd_spec_.fibermap)):\n",
        "  plt.plot(coadd_spec_.wave['b'],coadd_spec_.flux['b'][i])\n",
        "  plt.xlabel(\"Wavelength\")\n",
        "  plt.ylabel(\"Flux\")\n",
        "  plt.show()\n",
        "\n",
        "#Exercise:Add the redshift information and check all is consistent."
      ],
      "metadata": {
        "id": "NwZD_lviizgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, lets see the deltas associated to these spectra"
      ],
      "metadata": {
        "id": "RJHcxytTjaTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w=np.in1d(metadata[\"TARGETID\"],zcat[\"TARGETID\"])\n",
        "deltas=deltas[w]"
      ],
      "metadata": {
        "id": "sWrGysarRS6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Note thes in general will not be in the same order as above, we need to fix this...\n",
        "for i in range(len(deltas)):\n",
        "  plt.plot(wavelength,deltas[i])\n",
        "  plt.xlabel(\"Wavelength\")\n",
        "  plt.ylabel(\"Delta\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "tA7GNpS5lwmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Exercise: Make plots of the continuum and the weights."
      ],
      "metadata": {
        "id": "zb6AWovuU1hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a class=\"anchor\" id=\"autocorrelation\"></a>\n",
        "## Computing the auto-correlation function.\n",
        "\n",
        "We will use the [picca](https://github.com/igmhub/picca/tree/master) code. The  main reference for what is this code doing is (Gordon et.al 2023)[https://arxiv.org/abs/2308.10950]"
      ],
      "metadata": {
        "id": "nwcoP7SBVTPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(lya_dir+'/Correlations')\n",
        "!pwd"
      ],
      "metadata": {
        "id": "zHxg_1SMydV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#With this instruction we can compute the Lya auto correlation. We limited it to use only 1000 spectra, for speedness, but for using all the deltas available you can remove the --nspec 1000 flag\n",
        "!picca_cf.py --out cf_lya_lya.fits.gz --in-dir /content/drive/MyDrive/Bucaramanga/desi_edr/fuji/lya/Delta/ --nspec 1000"
      ],
      "metadata": {
        "id": "dOEbx5dh0X1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#To compute the complete distortion Matrix but still do it in a reasonable time change the --nspec 1000 flag to --rej 0.99\n",
        "!picca_dmat.py --out dmat.fits.gz --in-dir /content/drive/MyDrive/Bucaramanga/desi_edr/fuji/lya/Delta/ --nspec 1000"
      ],
      "metadata": {
        "id": "oR-tmuYI6AOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!picca_export.py --data cf_lya_lya.fits.gz --dmat dmat.fits.gz --out cf_lya_lya-exp.fits.gz"
      ],
      "metadata": {
        "id": "ESqf3kfV_eBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets check that all the produced files are in place\n",
        "!ls"
      ],
      "metadata": {
        "id": "-9-7RlHQ0gLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"Fig4_auto_corr_wedge.npz\"):\n",
        "  !wget https://zenodo.org/records/8244702/files/Fig4_auto_corr_wedge.npz?download=1\n",
        "  !wget https://zenodo.org/records/8244702/files/wedges.py?download=1\n",
        "  !mv Fig4_auto_corr_wedge.npz?download=1 Fig4_auto_corr_wedge.npz\n",
        "  !mv wedges.py?download=1 wedges.py\n",
        "  print(\"Downloaded Fig4_auto_corr_wedge.npz\")\n",
        "  print(\"Downloaded wedges.py\")\n",
        "else:\n",
        "  print(\"EDR CF files from Gordon 2023 are already on disk\")\n",
        "\n",
        "#Read the file with the EDR+M2 correlation function\n",
        "Gordon2023=np.load(\"Fig4_auto_corr_wedge.npz\")\n",
        "from wedges import Wedge"
      ],
      "metadata": {
        "id": "kflnQtC_CSB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create a function that plot the results, and compares with eBOSS DR16 results.\n",
        "def plot_cf(file_xis,xi_edr,rps=(-300,300,150), power=2,\n",
        "                 mus=[1., 0.95, 0.8, 0.5, 0], figsize=(6, 7),\n",
        "                 absMus=True, label=None,labels=None,colors=None):\n",
        "\n",
        "    f, (axs) = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\n",
        "\n",
        "    for k,file_xi in enumerate(file_xis):\n",
        "        #- Read correlation function and covariance matrix\n",
        "        h = fitsio.FITS(file_xi)\n",
        "        try:\n",
        "            da = h[1]['DA_BLIND'][:]\n",
        "        except:\n",
        "            da = h[1]['DA'][:]\n",
        "        co = h[1]['CO'][:]\n",
        "        hh = h[1].read_header()\n",
        "        rpmin = hh['RPMIN']\n",
        "        rpmax = hh['RPMAX']\n",
        "        rtmin = 0\n",
        "        rtmax = hh['RTMAX']\n",
        "        nrp = hh['NP']\n",
        "        nrt = hh['NT']\n",
        "        h.close()\n",
        "\n",
        "        j=0\n",
        "\n",
        "        for i, (mumax,mumin) in enumerate(zip(mus[:-1],mus[1:])):\n",
        "            b = picca.wedgize.wedge(mumin=mumin, mumax=mumax,\n",
        "                                rpmin=rpmin, rpmax=rpmax,\n",
        "                                rtmin=rtmin, rtmax=rtmax,\n",
        "                                nrt=nrt, nrp=nrp, absoluteMu=absMus,\n",
        "                                rmin=0., rmax=min(rpmax, rtmax),\n",
        "                                nr=min(nrt, nrp))\n",
        "            r,d,c = b.wedge(da,co)\n",
        "\n",
        "            nrows = 2\n",
        "\n",
        "                        #-- Wedges and best model\n",
        "            y = d*r**power\n",
        "            dy = np.sqrt(c.diagonal())*r**power\n",
        "\n",
        "\n",
        "\n",
        "            ###\n",
        "            b2 = Wedge(mu=(mumin,mumax),\n",
        "              rp=rps,\n",
        "              rt=(0,200,50),\n",
        "              r=(0., 200., 50))\n",
        "\n",
        "            xi=xi_edr['fugu_xi']\n",
        "            cov=xi_edr['fugu_cov']\n",
        "\n",
        "            r2,d2,c2=b2.__call__(xi,cov)\n",
        "            c2 = np.sqrt(np.diagonal(c2))\n",
        "            y2 = d2*r2**power\n",
        "            dy2 =c2*r**power\n",
        "            ####\n",
        "            if absMus:\n",
        "                if j==0:\n",
        "                    axs[j//2][j%2].errorbar(\n",
        "                    r, y, dy, fmt=\".\",label=labels[k],color=colors[k],alpha=0.7)\n",
        "                    axs[j//2][j%2].errorbar(\n",
        "                    r2, y2, dy2, fmt=\".\",label='Gordon et. al 2023',color='b',alpha=0.7)\n",
        "                    axs[j//2][j%2].axvline(100)\n",
        "\n",
        "                else:\n",
        "                    axs[j//2][j%2].errorbar(\n",
        "                        r, y, dy, fmt=\".\",color=colors[k],alpha=0.7)\n",
        "                    axs[j//2][j%2].errorbar(\n",
        "                        r2, y2, dy2, fmt=\".\",color='b',alpha=0.7)\n",
        "                    axs[j//2][j%2].axvline(100)\n",
        "            else:\n",
        "                axs[j//2][j%2].errorbar(\n",
        "                    r, y, dy, fmt=\"o\")\n",
        "                axs[j//2][j%2].errorbar(\n",
        "                    r2, y2, dy2, fmt=\"o\")\n",
        "\n",
        "            axs[j//2][j%2].set_ylabel(r\"$r^{power}\\xi(r)$\".format(power=power))\n",
        "            if j//2==1:\n",
        "                axs[j//2][j%2].set_xlabel(r\"$r \\, [h^{-1}\\, \\mathrm{Mpc}]$\")\n",
        "            axs[j//2][j%2].legend(loc=\"best\", fontsize=12)\n",
        "            #axs[j//2][j%2].grid(True)\n",
        "            j+=1\n",
        "        axs[0][0].set_title(r\"${}<\\mu<{}$\".format(0.95,1))\n",
        "        axs[0][1].set_title(r\"${}<\\mu<{}$\".format(0.8,0.95))\n",
        "        axs[1][0].set_title(r\"${}<\\mu<{}$\".format(0.5,8))\n",
        "        axs[1][1].set_title(r\"${}<\\mu<{}$\".format(0,0.5))\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0v1kANZNpsdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf=\"cf_lya_lya-exp.fits.gz\"\n",
        "\n",
        "plot_cf([cf],Gordon2023,rps=(0,300,75), labels=[\"EDR test\"],colors=['k'])"
      ],
      "metadata": {
        "id": "phRNwG40FVsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf_full=\"cf_lya_lya-exp-full.fits.gz\"\n",
        "plot_cf([cf_full],Gordon2023,rps=(0,300,75), labels=[\"DESI EDR\"],colors=['k'])"
      ],
      "metadata": {
        "id": "_aplue96Gont"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "my3IsDL0XDLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to compute the cross-correlation function. For this you will need the quasar catalog, you can try to derive it from the full catalog we have been working, but it would be better to use another VAC, the [BAL catalog](https://data.desi.lbl.gov/doc/releases/edr/vac/balqso/). This is very similar to actual catalog that was used in [Gordon et. al 2023](https://arxiv.org/abs/2308.10950).\n",
        "\n",
        "The picca instructions to use are picca_xcf.py, picca_xdmat.py, and picca_export.py. You can see the required arguments by requesting --help"
      ],
      "metadata": {
        "id": "dgaRcRWWm99_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EOFGw8Yynkrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}